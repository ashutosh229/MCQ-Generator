{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e80c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import os \n",
    "import json\n",
    "import pandas as pd \n",
    "import traceback \n",
    "from dotenv import load_dotenv \n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b49711-f70f-4c21-9d2c-1dd8d76f90c8",
   "metadata": {},
   "source": [
    "# Basics \n",
    "There are two types of packages in python: local and global. Local packages are the ones which are made in the local workspace by the developer and the global packages are the ones which are made by developers out there and dumped in the global network, from where people can install them and use them in their tasks.\n",
    "\n",
    "The global packages are easily identifiable because they are installed using the pip command and they are also present in the current environment after the installation, but for identifying the local package, there is a convention in python that the package should contain the __init__.py file. If this package gets dumped in the pypy repository then it will become the global package and other developers can install the package and use it using pip.\n",
    "\n",
    "We can also install our local package directly into the current local environment and for that purpose, we use the setup.py file\n",
    "\n",
    "# Environment Variables\n",
    "The environment variables are the variables which contain the information which is needed to be kept secret and therefore we should be storing somewhere in the local system which is not deployable and exposable to the network. There are two ways to do: Either we can store the information in the environment variables of the local system and use the os module to fetch the key value pair; or use the .env in the local workspace only,store everything there and fetch the value from there using the load_dotenv function in the dotenv module; or we can also fetch the value of the variable using the cmd by writing the import and export commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34e05e8-cd6c-41db-928a-a13c1e07e438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea4e222f-fa02-4af5-bb5c-6cd5ea34bee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583cd110-a8b4-4214-8579-4621f2093e11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=key,model_name=\"gpt-3.5-turbo\",temperature=0.7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2ef476-dc53-4e6c-8ba2-87581e35a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"responce.json\",\"r\") as f:\n",
    "    response_json = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e8a41de-2e39-48eb-b80a-10f3f61ea3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "Text: {text}\n",
    "You are an expert MCQ maker.Given the above text, it is your job to create a quiz of {number} multiple choice questions for {subject} students in {tone}.\n",
    "Make sure that the questions are not repeated and check all the questions to be conforminated.Make sure to format your response like RESPONSE_JSON below\n",
    "and use it as a guide. Ensure to make {number} MCQs\n",
    "###RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#github se dekh lena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c340f9b-cdb1-4334-8353-472c3f5764f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    input_variables = [\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "    template=template\n",
    "    \n",
    ")\n",
    "\n",
    "#github se dekh lena \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be04ffb0-d509-463e-b521-07ceb2854180",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm,prompt=prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee484bf-5b30-40ab-9617-fd5039bae415",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = \"\"\"\n",
    "You are an expert in english grammar and also a writer. Given a multiple choice quiz for {subject}, you need to evaluate the complexity of the  \n",
    "question and give a complete analysis of the quiz if the quiz is not at per with the cognitive and analytical\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#github se dekh lena "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932d2649-05ec-4008-87ac-702dd876320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_analysis = LLMChain(llm=llm,prompt=prompt2,output_key=\"quiz_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca944ca-d641-426b-b29c-8e239cd3bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_chain = SequentialChain(chains = [chain,chain_analysis],input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],output_variables=[\"quiz\",\"quiz_analysis\"],verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2aa71-8b32-409c-bc3c-5dca268cb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"this is the path of the data.txt file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9dfe0c-0073-4c1e-8bb4-4f974ce9b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH,\"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532d4a66-5796-4418-837d-85ed893f588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = json.dump(response_json) #converting to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41d36cdf-d172-4e38-aabb-10954c8c5090",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_chain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_openai_callback() \u001b[38;5;28;01mas\u001b[39;00m cb:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mgenerate_chain\u001b[49m(\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m         \n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m         \n\u001b[0;32m      8\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'generate_chain' is not defined"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = generate_chain(\n",
    "        {},\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ed443-028b-4da8-8e7d-e6f5a11d0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = response.get(\"quiz\")\n",
    "quiz = json.load(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ad6232-5b8e-4ff8-a437-9895b48f7f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd99062-1c4c-4e61-8ea2-6632b549448e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2785140-ca8d-4f57-87b4-889c90fa0dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10002f-1637-46d6-8cc3-5b5ceb0f2f04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05840d6-a1e9-42b3-95ff-54eb1fb219ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
